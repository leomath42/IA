{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "733f6717",
   "metadata": {},
   "source": [
    "# T3 de Inteligência Artificial\n",
    "\n",
    "Aluno: Leonardo Souza\n",
    "\n",
    "Professor: Eduardo Bezerra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a4492d",
   "metadata": {},
   "source": [
    "O objetivo deste trabalho é a implementação do algoritmo Q-Learning pelo método de aproximação linear.\n",
    "\n",
    "O algoritmo será testado dentro do ambiente Taxi-v3 do OpenGym, para tal, será necessário instalar algumas dependências:\n",
    "\n",
    "    pip3 install gym==0.17.3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808b6773",
   "metadata": {},
   "source": [
    "### Testando a criação do ambiente Taxi-v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa0e1393",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+---------+\n|R: | : :G|\n| : | : : |\n| : : : : |\n| | : | :\u001b[43m \u001b[0m|\n|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n+---------+\n\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "env = gym.make(\"Taxi-v3\").env\n",
    "\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6\n183\n0\n283 -1 False {'prob': 1.0}\n"
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "action = env.action_space.sample() # Seleciona ação a executar\n",
    "new_state, reward, done, info = env.step(action)\n",
    "print(env.action_space.n)\n",
    "\n",
    "print(state)\n",
    "print(action)\n",
    "print(new_state, reward, done, info)\n",
    "\n",
    "\n",
    "def feature_manhattan_distance_taxi_passenger(state, action):\n",
    "    l, c, p, d = env.unwrapped.decode(state)\n",
    "    p = env.unwrapped.locs[p]\n",
    "    \n",
    "    return abs(l - p[0]) + abs(c - p[1])\n",
    "\n",
    "\n",
    "def feature_manhattan_distance_taxi_destiny(state, action):\n",
    "    l, c, p, d = env.unwrapped.decode(state)\n",
    "    d = env.unwrapped.locs[d]\n",
    "\n",
    "    return abs(l - d[0]) + abs(c - d[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.67955667 0.74524331]\n[5, 4]\n<class 'numpy.ndarray'>\n[3.39778335 2.98097324]\n6.378756591130507\n6.378756591130507\n"
     ]
    }
   ],
   "source": [
    "# print(feature_manhattan_distance_taxi_passenger(state, action))\n",
    "# print(feature_manhattan_distance_taxi_passenger(new_state, action))\n",
    "\n",
    "# a = np.array([feature_manhattan_distance_taxi_passenger, feature_manhattan_distance_taxi_destiny])\n",
    "b = np.random.rand(a.size)\n",
    "print(b)\n",
    "features = [f(state, action) for f in  [feature_manhattan_distance_taxi_passenger, feature_manhattan_distance_taxi_destiny]]\n",
    "# features = np.array([f(state, action) for f in  [feature_manhattan_distance_taxi_passenger, feature_manhattan_distance_taxi_destiny]])\n",
    "print(features)\n",
    "features = np.array([5, 4])\n",
    "print(type(features))\n",
    "\n",
    "print(features * b)\n",
    "print((features * b).sum())\n",
    "print( b @ features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6129721c",
   "metadata": {},
   "source": [
    "## Implementação do Q-Learning Linear"
   ]
  },
  {
   "source": [
    "### Definição dos hyperparâmetros"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Implementação das Classe QLearningLinear"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189fe22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class QLearningLinear\n",
    "class QLearningLinear(object):\n",
    "    \n",
    "    def __init__(self, learning_rate = 0.7, features:list):\n",
    "        # cria um numpy array de pesos sendo 1:n, onde n representa o número de features\n",
    "        self.weigths = np.random.rand(len(features))\n",
    "        # covnerte a lista de features para um numpy array.\n",
    "        self.features = features\n",
    "    \n",
    "    def Q(state, action):\n",
    "        \"\"\"\n",
    "            Q(S,A) \n",
    "        \"\"\"\n",
    "        f_values = [f(state, action) for f in  [feature_manhattan_distance_taxi_passenger, feature_manhattan_distance_taxi_destiny]]\n",
    "        f_values = np.array(f_values)\n",
    "\n",
    "        return (self.weigths * f_values).sum()\n",
    "        \n",
    "\n",
    "    def learn(self):\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00a3c8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}